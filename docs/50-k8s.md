# AIStore Kubernetes Observability

This document explains how to implement and use observability features for AIStore deployments in Kubernetes environments. Kubernetes provides additional tools and patterns for monitoring that complement AIStore's built-in observability features.

## Kubernetes Monitoring Architecture

When deployed in Kubernetes, AIStore observability typically follows this architecture:

```
┌────────────────────────────────────────────────────────────┐
│                     Kubernetes Cluster                      │
│                                                            │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │  AIStore    │    │ Prometheus  │    │  Grafana    │     │
│  │   Pods      │───▶│  Operator   │───▶│   Pods      │     │
│  │             │    │             │    │             │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│        │                   │                  │            │
│        │                   │                  │            │
│        ▼                   ▼                  ▼            │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │ Kubernetes  │    │ AlertManager│    │ Persistent  │     │
│  │  Metrics    │    │    Pods     │    │  Storage    │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

## Prerequisites

- Kubernetes cluster with AIStore deployed
- [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack) or individual components:
  - Prometheus Operator
  - Prometheus Server
  - AlertManager
  - Grafana

## Deployment Methods

### Method 1: Using the AIS-K8s Repository

The [AIS-K8s repository](https://github.com/NVIDIA/ais-k8s) provides pre-configured monitoring for AIStore:

```bash
# Clone the repository
git clone https://github.com/NVIDIA/ais-k8s
cd ais-k8s

# Deploy AIStore with monitoring
helm install ais-deployment ./helm/ais --set monitoring.enabled=true
```

### Method 2: Manual Configuration with Prometheus Operator

If you're using a custom deployment:

1. Deploy Prometheus Operator using Helm:

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack
```

2. Create ServiceMonitor for AIStore:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ais-monitors
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: ais
  namespaceSelector:
    matchNames:
      - ais-namespace
  endpoints:
  - port: metrics
    interval: 15s
    path: /metrics
```

3. Apply the ServiceMonitor:

```bash
kubectl apply -f servicemonitor.yaml
```

## Configuring AIStore for Kubernetes Monitoring

Ensure AIStore pods expose Prometheus metrics properly:

1. AIStore ConfigMap should have Prometheus enabled:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ais-config
data:
  ais.json: |
    {
      "prometheus": {
        "enabled": true
      },
      // ...other config
    }
```

2. AIStore Service should expose metrics port:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ais-targets
  labels:
    app: ais
    component: target
spec:
  ports:
  - name: metrics
    port: 8081
    targetPort: 8081
  selector:
    app: ais
    component: target
```

## Kubernetes-specific Metrics

In addition to standard AIStore metrics, consider monitoring these Kubernetes-specific metrics:

### Pod Metrics

- `kube_pod_container_resource_usage_cpu_cores` - CPU usage by AIStore pods
- `kube_pod_container_resource_usage_memory_bytes` - Memory usage by AIStore pods
- `kube_pod_container_status_restarts_total` - Container restart count
- `kube_pod_status_phase` - Pod status (running, pending, failed)

### Volume Metrics

- `kubelet_volume_stats_available_bytes` - Available volume space
- `kubelet_volume_stats_capacity_bytes` - Total volume capacity
- `kubelet_volume_stats_used_bytes` - Used volume space

### Network Metrics

- `container_network_receive_bytes_total` - Network bytes received
- `container_network_transmit_bytes_total` - Network bytes transmitted
- `container_network_receive_packets_total` - Network packets received
- `container_network_transmit_packets_total` - Network packets transmitted

## Grafana Dashboards for Kubernetes

AIStore in Kubernetes benefits from multiple dashboard types:

### 1. AIStore Application Dashboard

Focus on AIStore-specific metrics:
- Throughput and latency
- Operation rates
- Error counts
- Rebalance status

### 2. Kubernetes Resource Dashboard

Focus on Kubernetes infrastructure:
- Pod resource usage (CPU, memory)
- Network traffic between nodes
- Volume usage and IOPS
- Pod restarts and health

### 3. Combined Operational Dashboard

Correlate application and infrastructure metrics:
- AIStore performance vs. resource usage
- Impact of pod restarts on operations
- Storage latency vs. Kubernetes volume metrics

## Example Dashboard Import

Import the AIStore Kubernetes dashboard:

1. Download the dashboard JSON from the ais-k8s repository
2. In Grafana, go to Dashboards > Import
3. Upload the JSON file or paste its contents
4. Select your Prometheus data source
5. Click Import

## Alerting in Kubernetes

Create Prometheus AlertManager rules for Kubernetes-specific issues:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ais-alerts
  namespace: monitoring
spec:
  groups:
  - name: ais.rules
    rules:
    - alert: AIStorePodRestartingFrequently
      expr: rate(kube_pod_container_status_restarts_total{namespace="ais-namespace"}[15m]) > 0.2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "AIStore pod restarting frequently"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting frequently"

    - alert: AIStoreVolumeNearlyFull
      expr: kubelet_volume_stats_available_bytes{namespace="ais-namespace"} / kubelet_volume_stats_capacity_bytes{namespace="ais-namespace"} < 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "AIStore volume nearly full"
        description: "Volume {{ $labels.persistentvolumeclaim }} is at {{ $value | humanizePercentage }} capacity"

    - alert: AIStoreHighNetworkTraffic
      expr: sum(rate(container_network_transmit_bytes_total{namespace="ais-namespace"}[5m])) > 1e9
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High network traffic"
        description: "Network traffic exceeds 1GB/s for 10 minutes"
```

Apply the rules:

```bash
kubectl apply -f alertrules.yaml
```

## Log Management in Kubernetes

### Centralized Logging Options

1. **ELK Stack (Elasticsearch, Logstash, Kibana)**:
   - Deploy using the Elastic Operator
   - Configure Filebeat as a DaemonSet to collect container logs

2. **Loki Stack**:
   - Lighter weight than ELK
   - Deploy with Promtail for log collection
   - Integrates well with Grafana

3. **Fluent Bit / Fluentd**:
   - Collect and forward logs to various backends
   - Configure as a DaemonSet

### Example Loki Stack Deployment

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
helm install loki grafana/loki-stack \
  --set promtail.enabled=true \
  --set grafana.enabled=true
```

Configure a Loki data source in Grafana and create log dashboards.

## Operational Best Practices

### Resource Allocation

- **Set resource requests and limits** for AIStore pods to ensure predictable performance
- Monitor actual usage vs. requests to optimize resource allocation

### Horizontal Pod Autoscaling

While AIStore targets don't typically use HPA, proxy nodes can benefit:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ais-proxy-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ais-proxy
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
```

### Pod Disruption Budgets

Protect AIStore availability during cluster operations:

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ais-target-pdb
spec:
  minAvailable: 60%
  selector:
    matchLabels:
      app: ais
      component: target
```

### Readiness and Liveness Probes

Ensure proper health checking:

```yaml
readinessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 60
  periodSeconds: 15
```

## Troubleshooting AIStore in Kubernetes

### Common Issues and Solutions

| Issue | Symptoms | Troubleshooting Commands |
|-------|----------|--------------------------|
| Pod won't start | Pod stuck in Pending state | `kubectl describe pod <pod-name>` |
| Configuration issues | Pod starts but AIStore service fails | `kubectl logs <pod-name>` |
| Performance degradation | High latency, low throughput | `kubectl top pod` |
| Network connectivity | Transport errors in logs | `kubectl exec <pod-name> -- ping <target>` |
| Storage issues | I/O errors, disk full | `kubectl exec <pod-name> -- df -h` |

### Collecting Debug Information

Script to collect comprehensive debug info:

```bash
#!/bin/bash
NAMESPACE="ais-namespace"
OUTPUT_DIR="ais-debug-$(date +%Y%m%d-%H%M%S)"
mkdir -p $OUTPUT_DIR

# Get all resources
kubectl get all -n $NAMESPACE -o wide > $OUTPUT_DIR/resources.txt

# Get pod descriptions
for pod in $(kubectl get pods -n $NAMESPACE -o name); do
  kubectl describe $pod -n $NAMESPACE > $OUTPUT_DIR/$(echo $pod | cut -d/ -f2)-describe.txt
done

# Get logs
for pod in $(kubectl get pods -n $NAMESPACE -o name); do
  kubectl logs $pod -n $NAMESPACE > $OUTPUT_DIR/$(echo $pod | cut -d/ -f2)-logs.txt
done

# Get configmaps
kubectl get configmaps -n $NAMESPACE -o yaml > $OUTPUT_DIR/configmaps.yaml

# Get metrics
kubectl top pods -n $NAMESPACE > $OUTPUT_DIR/pod-metrics.txt
kubectl top nodes > $OUTPUT_DIR/node-metrics.txt

# Get events
kubectl get events -n $NAMESPACE > $OUTPUT_DIR/events.txt

echo "Debug information collected in $OUTPUT_DIR"
```

## Further Reading

- [AIStore K8s Repository](https://github.com/NVIDIA/ais-k8s)
- [Prometheus Operator Documentation](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md)
- [Kubernetes Monitoring Best Practices](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/)
- [Loki Documentation](https://grafana.com/docs/loki/latest/)
